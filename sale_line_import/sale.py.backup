# -*- encoding: utf-8 -*-
###########################################################################
#    Module Writen to OpenERP, Open Source Management Solution
#    Migrated from v6 to v5 by Daniel Ingl√©s Andreu (danielingle@gmail.com)
#
#    Copyright (c) 2012 Vauxoo - http://www.vauxoo.com
#    All Rights Reserved.
#    info@vauxoo.com
############################################################################
#    Coded by: julio (julio@vauxoo.com)
############################################################################
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU Affero General Public License as
#    published by the Free Software Foundation, either version 3 of the
#    License, or (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU Affero General Public License for more details.
#
#    You should have received a copy of the GNU Affero General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
##############################################################################
import logging
import time
from osv import osv, fields
from tools.translate import _
from tools import config
import base64
import csv
import cStringIO
import tools

import re
import netsvc

_logger = logging.getLogger(__name__)

class sale_order(osv.osv):
    _inherit='sale.order'

    def import_data2(self, cr, uid, fields, datas, mode='init', current_module='', noupdate=False, context=None, filename=None):
        """
        Import given data in given module

        :param cr: database cursor
        :param uid: current user id
        :param fields: list of fields
        :param data: data to import
        :param mode: 'init' or 'update' for record creation
        :param current_module: module name
        :param noupdate: flag for record creation
        :param context: context arguments, like lang, time zone,
        :param filename: optional file to store partial import state for recovery
        :rtype: tuple

        This method is used when importing data via client menu.

        Example of fields to import for a sale.order::

            .id,                         (=database_id)
            partner_id,                  (=name_search)
            order_line/.id,              (=database_id)
            order_line/name,
            order_line/product_id/id,    (=xml id)
            order_line/price_unit,
            order_line/product_uom_qty,
            order_line/product_uom/id    (=xml_id)
        """
        if not context:
            context = {}
        def _replace_field(x):
            x = re.sub('([a-z0-9A-Z_])\\.id$', '\\1/.id', x)
            return x.replace(':id','/id').split('/')
        fields = map(_replace_field, fields)
        logger = netsvc.Logger()
        ir_model_data_obj = self.pool.get('ir.model.data')

        # mode: id (XML id) or .id (database id) or False for name_get
        def _get_id(model_name, id, current_module=False, mode='id'):
            if mode=='.id':
                id = int(id)
                obj_model = self.pool.get(model_name)
                dom = [('id', '=', id)]
                if obj_model._columns.get('active'):
                    dom.append(('active', 'in', ['True','False']))
                ids = obj_model.search(cr, uid, dom, context=context)
                if not len(ids):
                    raise Exception(_("Database ID doesn't exist: %s : %s") %(model_name, id))
            elif mode=='id':
                if '.' in id:
                    module, xml_id = id.rsplit('.', 1)
                else:
                    module, xml_id = current_module, id
                record_id = ir_model_data_obj._get_id(cr, uid, module, xml_id)
                ir_model_data = ir_model_data_obj.read(cr, uid, [record_id], ['res_id'], context=context)
                if not ir_model_data:
                    raise ValueError('No references to %s.%s' % (module, xml_id))
                id = ir_model_data[0]['res_id']
            else:
                obj_model = self.pool.get(model_name)
                ids = obj_model.name_search(cr, uid, id, operator='=', context=context)
                if not ids:
                    raise ValueError('No record found for %s' % (id,))
                id = ids[0][0]
            return id

        # IN:
        #   datas: a list of records, each record is defined by a list of values
        #   prefix: a list of prefix fields ['line_ids']
        #   position: the line to process, skip is False if it's the first line of the current record
        # OUT:
        #   (res, position, warning, res_id) with
        #     res: the record for the next line to process (including it's one2many)
        #     position: the new position for the next line
        #     res_id: the ID of the record if it's a modification
        def process_liness(self, datas, prefix, current_module, model_name, fields_def, position=0, skip=0):
            line = datas[position]
            row = {}
            warning = []
            data_res_id = False
            xml_id = False
            nbrmax = position+1

            done = {}
            for i in range(len(fields)):
                res = False
                if i >= len(line):
                    raise Exception(_('Please check that all your lines have %d columns.') % (len(fields),))

                field = fields[i]
                if field[:len(prefix)] <> prefix:
                    if line[i] and skip:
                        return False
                    continue

                # ID of the record using a XML ID
                if field[len(prefix)]=='id':
                    try:
                        data_res_id = _get_id(model_name, line[i], current_module, 'id')
                    except ValueError, e:
                        pass
                    xml_id = line[i]
                    continue

                # ID of the record using a database ID
                elif field[len(prefix)]=='.id':
                    data_res_id = _get_id(model_name, line[i], current_module, '.id')
                    continue

                # recursive call for getting children and returning [(0,0,{})] or [(1,ID,{})]
                if fields_def[field[len(prefix)]]['type']=='one2many':
                    if field[len(prefix)] in done:
                        continue
                    done[field[len(prefix)]] = True
                    relation_obj = self.pool.get(fields_def[field[len(prefix)]]['relation'])
                    newfd = relation_obj.fields_get(cr, uid, context=context)
                    pos = position
                    res = []
                    first = 0
                    while pos < len(datas):
                        res2 = process_liness(self, datas, prefix + [field[len(prefix)]], current_module, relation_obj._name, newfd, pos, first)
                        if not res2:
                            break
                        (newrow, pos, w2, data_res_id2, xml_id2) = res2
                        nbrmax = max(nbrmax, pos)
                        warning += w2
                        first += 1
                        if (not newrow) or not reduce(lambda x, y: x or y, newrow.values(), 0):
                            break
                        res.append( (data_res_id2 and 1 or 0, data_res_id2 or 0, newrow) )

                elif fields_def[field[len(prefix)]]['type']=='many2one':
                    relation = fields_def[field[len(prefix)]]['relation']
                    if len(field) == len(prefix)+1:
                        mode = False
                    else:
                        mode = field[len(prefix)+1]
                    res = line[i] and _get_id(relation, line[i], current_module, mode) or False

                elif fields_def[field[len(prefix)]]['type']=='many2many':
                    relation = fields_def[field[len(prefix)]]['relation']
                    if len(field) == len(prefix)+1:
                        mode = False
                    else:
                        mode = field[len(prefix)+1]

                    # TODO: improve this by using csv.csv_reader
                    res = []
                    if line[i]:
                        for db_id in line[i].split(config.get('csv_internal_sep')):
                            res.append( _get_id(relation, db_id, current_module, mode) )
                    res = [(6,0,res)]

                elif fields_def[field[len(prefix)]]['type'] == 'integer':
                    res = line[i] and int(line[i]) or 0
                elif fields_def[field[len(prefix)]]['type'] == 'boolean':
                    res = line[i].lower() not in ('0', 'false', 'off')
                elif fields_def[field[len(prefix)]]['type'] == 'float':
                    res = line[i] and float(line[i]) or 0.0
                elif fields_def[field[len(prefix)]]['type'] == 'selection':
                    for key, val in fields_def[field[len(prefix)]]['selection']:
                        if line[i] in [tools.ustr(key), tools.ustr(val)]:
                            res = key
                            break
                    if line[i] and not res:
                        logger.notifyChannel("import", netsvc.LOG_WARNING,
                                _("key '%s' not found in selection field '%s'") % \
                                        (line[i], field[len(prefix)]))
                        warning += [_("Key/value '%s' not found in selection field '%s'") % (line[i], field[len(prefix)])]
                else:
                    res = line[i]

                row[field[len(prefix)]] = res or False

            result = (row, nbrmax, warning, data_res_id, xml_id)
            return result

        fields_def = self.fields_get(cr, uid, context=context)

        if config.get('import_partial', False) and filename:
            data = pickle.load(file(config.get('import_partial')))
            original_value = data.get(filename, 0)

        position = 0
        while position<len(datas):
            res = {}

            (res, position, warning, res_id, xml_id) = \
                    process_liness(self, datas, [], current_module, self._name, fields_def, position=position)
            if len(warning):
                cr.rollback()
                return (-1, res, 'Line ' + str(position) +' : ' + '!\n'.join(warning), '')

            try:
                id = ir_model_data_obj._update(cr, uid, self._name,
                     current_module, res, mode=mode, xml_id=xml_id,
                     noupdate=noupdate, res_id=res_id, context=context)
            except Exception, e:
                return (-1, res, 'Line ' + str(position) +' : ' + tools.ustr(e), '')

            if config.get('import_partial', False) and filename and (not (position%100)):
                data = pickle.load(file(config.get('import_partial')))
                data[filename] = position
                pickle.dump(data, file(config.get('import_partial'), 'wb'))
                if context.get('defer_parent_store_computation'):
                    self._parent_store_compute(cr)
                cr.commit()

        if context.get('defer_parent_store_computation'):
            self._parent_store_compute(cr)
        return (position, 0, 0, 0)

    
    def import_data_line(self, cr, uid, ids, fdata, favalidate, context={}):
        order=self.browse(cr, uid, ids)
        #order=self.pool.get('sale.order').browse(cr,uid,ids)
        input=cStringIO.StringIO(fdata)
        input.seek(0)
        data = list(csv.reader(input, quotechar='"' or '"', delimiter=';'))
        data[0].append('order_id.id')
        try:
            list_prod=data[0].index('product_id')
        except: 
            list_prod=[]
        msg=''
        pmsg=''
        not_products=[]
        new_products_prices=[]

        _logger.error("DATA_data : %r", data)

        for dat in data[1:]:
            datas=[]
            data2=list(data[0])
            dat.append(ids)
            try:
                prod_name=dat[list_prod]
            except:
                prod_name=False
            context.update({'partner_id':order.partner_id.id})
            #if not prod_name and 'name' in data2:
            #prod_name = dat[data2.index('name')]
            uom_name = 'product_uom' in data2 and dat[data2.index('product_uom')] or ''
            uom_name_search=uom_name and self.pool.get('product.uom').name_search(cr,uid,uom_name,context=context) or False
            uom_id = uom_name_search and uom_name_search[0][0] or False
            prod_name_search=prod_name and self.pool.get('product.product').name_search(cr,uid,prod_name,context=context) or False
            prod_id = prod_name_search and prod_name_search[0][0] or False
            _logger.error("prod_id : %r", prod_id)
            _logger.error("prod_name_search : %r", prod_name_search)
            lines=prod_id and self.pool.get('sale.order.line').product_id_change(cr, uid, [], order.pricelist_id.id,prod_id,                       
                                            qty='product_uom_qty' in data2 and float(dat[data2.index('product_uom_qty')]) or 0,uom=uom_id, 
                                            qty_uos=0, uos=False, name='', partner_id=order.partner_id.id,
                                            lang=False, update_tax=True, date_order=order.date_order, packaging=False, fiscal_position=False).get('value',False) or {}
            _logger.error("lines : %r", lines)
            _logger.error("prod_id : %r", prod_id)


            prod_id and lines.update({'product_id': prod_name_search[0][1], 'product_uos': lines['product_uos'] and self.pool.get('product.uom').browse(cr,uid,lines['product_uos']).name or False})

            if not lines and prod_name:
                not_products.append(prod_name)
            if not prod_name:
                self.pool.get('sale.order.line').import_data(cr, uid, data2, [dat], 'init', '')
            for lin in range(len(lines.keys())):
                if lines.keys()[lin] not in data[0]:
                    if lines.keys()[lin] in ('tax_id','product_uom','product_packaging'):
                        field_val=str(lines.keys()[lin])
                        field_val=field_val+'.id'
                        data2.append(field_val)
                        vals_many =str( lines[lines.keys()[lin]] ).replace('[','').replace(']','').replace('False','')
                        dat.append( vals_many )
                    else:
                        data2.append(lines.keys()[lin])
                        dat.append(lines[lines.keys()[lin]])

                else:
                    val_str=dat[data[0].index(lines.keys()[lin])]
                    val_str_2=lines[lines.keys()[lin]]
                    if lines.keys()[lin] in ('product_uom','product_uos'): 
                        val_str_2=self.pool.get('product.uom').browse(cr,uid,val_str_2).name
                        val_str=dat[data[0].index(lines.keys()[lin])]
                    if lines.keys()[lin]=='price_unit':
                        product_price=[]
                        product_price.append(prod_name)
                        val_str=float(dat[data[0].index(lines.keys()[lin])])
                        val_str_2=float(lines[lines.keys()[lin]])
                        if tools.ustr(val_str) <> tools.ustr(val_str_2):
                            product_price.append(val_str)
                            product_price.append(val_str_2)
                            new_products_prices.append(product_price)
                    try:
                        val_str = float(val_str)
                        val_str_2 = float(val_str_2)
                    except:
                        pass
                    if val_str <> val_str_2:
                        if not lines.keys()[lin]=='price_unit':
                            pmsg+=_('%s , Field: %s, CSV: %s, OPEN: %s \n') % (tools.ustr(prod_name),lines.keys()[lin],tools.ustr(dat[data[0].index(lines.keys()[lin])]),tools.ustr(val_str_2))
                        if favalidate:
                            dat[data[0].index(lines.keys()[lin])] = val_str_2
                        else:
                            dat[data[0].index(lines.keys()[lin])] = val_str or val_str_2
            datas.append(dat)
            _logger.error("DATA_datas: %r", datas)
            try:
                lines and self.pool.get('sale.order.line').import_data(cr, uid, data2, datas, 'init', '',context=context) or False
            except Exception, e:
                return False
            data2=[]
        
        msg+=_('Do not you find reference:')
        msg+='\n'
        for p in not_products:
            msg+='%s \n'% (tools.ustr(p))
        msg+='\n'
        msg+=_('Warning of price difference, CSV VS System in the following products:')
        msg+='\n'
        for p in new_products_prices:
            p2=(','.join(map(str,p)))
            msg+='%s \n'%(p2)
        msg+='\n'
        msg+=_('Warning differences in other fields, CSV VS System in the following products and fields:')
        msg+='\n %s '%(pmsg)
        msg2=tools.ustr(pmsg)
        msg=tools.ustr(msg)+'%s '%(msg2)
        return msg
        
sale_order()